# MVP 必需变量
APP_ENV=dev

# ========== 按 intent/节点 使用不同模型（定义在 packages/llm/model_config.py）==========
# 未设置 *档位* 变量时，回退到下面的「全局」MODEL_BASE_URL / MODEL_NAME / API_KEY。
# 档位与节点对应：chat=闲聊/公司介绍, collect=问参+采集, qa=RAG 问答+推荐话术。

# 全局回退（所有档位未单独设置时使用）
MODEL_BASE_URL=http://localhost:8000/v1
MODEL_NAME=deepseek-r1-lora
API_KEY=dummy

# --- 非 GPT 的 LLM 节点：chat / collect_recommend_params / collect_requirements / recommend ---
# 默认用 OpenAI gpt-4o 跑全流程（需设置 OPENAI_API_KEY）
# LLM_BACKEND=openai
# OPENAI_API_KEY=sk-xxx
# 改用本地 Hugging Face 时：LLM_BACKEND=huggingface，并安装 pip install -e ".[chat-hf]"
# LLM_BACKEND=huggingface
# MODEL_ID=Milkfish033/deepseek-r1-1.5b-merged

# --- 档位 collect：问参、采集（节点 collect_recommend_params, collect_requirements）---
# MODEL_COLLECT_BASE_URL=http://localhost:8000/v1
# MODEL_COLLECT_NAME=deepseek-r1-lora
# MODEL_COLLECT_API_KEY=dummy

# --- 档位 qa：RAG 问答 + 推荐话术（节点 rag_query, recommend）---
# MODEL_QA_BASE_URL=https://api.deepseek.com/v1
# MODEL_QA_NAME=deepseek-chat
# MODEL_QA_API_KEY=sk-xxx

# 意图分类：规则未命中时用外部小模型（预留，在 packages/llm/intent_classifier.py 中调用）
# INTENT_MODEL_BASE_URL=http://localhost:8001
# INTENT_MODEL_PATH=/v1/classify
